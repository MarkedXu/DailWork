{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "385998be-2f98-49d7-b68a-3190907ef1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4], dtype=torch.int32)\n",
      "tensor([[[-0.0578, -0.4552, -0.2449,  0.5633],\n",
      "         [ 1.0674, -0.4888,  0.5003,  1.1752],\n",
      "         [-0.8320, -1.2310,  0.3404, -0.8350],\n",
      "         [-1.0298, -0.9438, -1.2155,  0.1495]],\n",
      "\n",
      "        [[ 0.7927,  2.3546,  0.2898, -1.3661],\n",
      "         [ 1.7138,  0.8618, -0.3444,  0.9352],\n",
      "         [ 0.0902, -1.0603,  1.2608, -2.2013],\n",
      "         [ 0.3592, -0.1886, -1.3319, -0.1157]]])\n",
      "tensor([[[-5.7835e-02, -4.5516e-01, -1.0000e+09, -1.0000e+09],\n",
      "         [ 1.0674e+00, -4.8878e-01, -1.0000e+09, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]],\n",
      "\n",
      "        [[ 7.9267e-01,  2.3546e+00,  2.8975e-01, -1.3661e+00],\n",
      "         [ 1.7138e+00,  8.6184e-01, -3.4442e-01,  9.3525e-01],\n",
      "         [ 9.0245e-02, -1.0603e+00,  1.2608e+00, -2.2013e+00],\n",
      "         [ 3.5916e-01, -1.8861e-01, -1.3319e+00, -1.1574e-01]]])\n",
      "tensor([[[0.5980, 0.4020, 0.0000, 0.0000],\n",
      "         [0.8258, 0.1742, 0.0000, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500]],\n",
      "\n",
      "        [[0.1541, 0.7349, 0.0932, 0.0178],\n",
      "         [0.4967, 0.2119, 0.0634, 0.2280],\n",
      "         [0.2154, 0.0682, 0.6946, 0.0218],\n",
      "         [0.4194, 0.2425, 0.0773, 0.2608]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 关于word embeding序列建模\n",
    "# Consider the source sentence and the target sentence\n",
    "# Construct the sequences whose characters are represented by their indexes in the word table\n",
    "batch_size = 2\n",
    "\n",
    "# size of the words\n",
    "max_num_src_words = 8\n",
    "max_num_target_words = 8\n",
    "\n",
    "model_dim = 8\n",
    "\n",
    "# define the max len of sequences\n",
    "max_src_seq_len = 5\n",
    "max_target_seq_len = 5\n",
    "max_position_len = 5\n",
    "\n",
    "# src_len = torch.randint(2, 5, (batch_size,))\n",
    "# target_len = torch.randint(2, 5, (batch_size,))\n",
    "\n",
    "src_len = torch.Tensor([2,4]).to(torch.int32)\n",
    "target_len = torch.Tensor([4,3]).to(torch.int32)\n",
    "\n",
    "# the sequence of the index about the words\n",
    "# and have been done the padding, see the 0 as the default\n",
    "src_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_num_src_words, (L,)), (0, max(src_len) - L)), 0)\\\n",
    "                     for L in src_len])\n",
    "target_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_num_target_words, (L,)), (0, max(target_len) - L)), 0)\\\n",
    "                     for L in target_len])\n",
    "\n",
    "\n",
    "# Construct the word embedding \n",
    "src_embedding_table = nn.Embedding(max_num_src_words + 1, model_dim)\n",
    "target_embedding_table = nn.Embedding(max_num_target_words + 1, model_dim)\n",
    "src_embedding = src_embedding_table(src_seq)\n",
    "target_embedding = target_embedding_table(target_seq)\n",
    "\n",
    "# Construct the position embedding\n",
    "pos_mat = torch.arange(max_position_len).reshape((-1,1))\n",
    "i_mat = torch.pow(10000,torch.arange(0,8,2).reshape((1,-1))/model_dim)\n",
    "pe_embedding_table = torch.zeros(max_position_len, model_dim)\n",
    "pe_embedding_table[:, 0::2] = torch.sin(pos_mat/i_mat)\n",
    "pe_embedding_table[:, 1::2] = torch.cos(pos_mat/i_mat)\n",
    "\n",
    "# print(pe_embedding_table)\n",
    "\n",
    "pe_embedding = nn.Embedding(max_position_len, model_dim)\n",
    "pe_embedding.weight = nn.Parameter(pe_embedding_table, requires_grad=False)\n",
    "\n",
    "src_pos = torch.cat([torch.unsqueeze(torch.arange(max(src_len)),0) for _ in src_len]).to(torch.int32)\n",
    "target_pos = torch.cat([torch.unsqueeze(torch.arange(max(target_len)),0) for _ in target_len]).to(torch.int32)\n",
    "# print(src_pos)\n",
    "\n",
    "src_pe_embedding = pe_embedding(src_pos)\n",
    "target_pe_embedding = pe_embedding(target_pos)\n",
    "# print(src_pe_embedding)\n",
    "# print(target_pe_embedding)\n",
    "\n",
    "# Construct the encoder's self-attention mask\n",
    "# The shape of the mask:[batch_size, max_src_len, max_src_len],the output is -1 or thr -inf\n",
    "valid_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L), (0, max(src_len) - L)), 0) \\\n",
    "                                               for L in src_len]),2)\n",
    "valid_encoder_pos_matrix = torch.bmm(valid_encoder_pos, valid_encoder_pos.transpose(1,2))\n",
    "invalid_encoder_pos_matrix = 1 - valid_encoder_pos_matrix\n",
    "mask_encoder_self_attention = invalid_encoder_pos_matrix.to(torch.bool)\n",
    "\n",
    "score = torch.randn(batch_size, max(src_len), max(src_len))\n",
    "masked_score = score.masked_fill(mask_encoder_self_attention, -1e9)\n",
    "prob = F.softmax(masked_score, -1)\n",
    "\n",
    "print(src_len)\n",
    "print(score)\n",
    "print(masked_score)\n",
    "print(prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9979bc8-0280-466f-bd6c-05ef21aecc73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
