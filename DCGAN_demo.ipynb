{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a9bfc9d-d8bc-4dd0-a44b-4441b25fbb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 11:25:26.969395: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64\n",
      "2022-02-27 11:25:26.969460: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import (Activation, BatchNormalization, Dense, Dropout, Flatten, Reshape)\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import adam_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84960c8-d609-4481-9187-e33e05ffd6ec",
   "metadata": {},
   "source": [
    "### 模型输入维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86c78759-3b91-4de9-8c81-22cb68de73fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "z_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becb7237-db5b-403a-bba8-e3899dd8a5ad",
   "metadata": {},
   "source": [
    "### DCGAN生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69faa1f0-4b36-487f-996f-46032899dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(z_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256*7*7, input_dim=z_dim))\n",
    "    model.add(Reshape((7,7,256)))\n",
    "    \n",
    "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25691eca-84be-4543-9129-03e2694e8b80",
   "metadata": {},
   "source": [
    "### DCGAN鉴别器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62b0d2ce-911b-41ed-b4dc-152f45ba3004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=3,strides=2, input_shape=img_shape, padding='same'))\n",
    "    \n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, input_shape=img_shape, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, input_shape=img_shape, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991fa910-4fbd-4379-8d44-191ed18fc086",
   "metadata": {},
   "source": [
    "### 构建并运行DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6fc61ff-5c14-493d-85cb-3b89dc870ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1979da8c-882d-4953-af07-9ace54ccba1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 11:25:41.087600: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64\n",
      "2022-02-27 11:25:41.087619: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-27 11:25:41.087635: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ryan\n",
      "2022-02-27 11:25:41.087639: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ryan\n",
      "2022-02-27 11:25:41.087692: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-02-27 11:25:41.087721: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.103.1\n",
      "2022-02-27 11:25:41.088263: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "discriminator = build_discriminator(img_shape)\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                     optimizer=adam_v2.Adam(),\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "generator = build_generator(z_dim)\n",
    "\n",
    "discriminator.trainable = False\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam_v2.Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b7031b-ea08-4d3a-94e7-92c153c0e7f2",
   "metadata": {},
   "source": [
    "### 训练DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a195d56b-3de6-4d5c-a3a2-7901a78c33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "iteration_checkpoints = []\n",
    "\n",
    "def train(iterations, batch_size, sample_interval):\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "    X_train = X_train/127.5 - 1.0\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "    real = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "        \n",
    "        z = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = generator.predict(z)\n",
    "        \n",
    "        # 生成一批伪图像，训练鉴别器\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, real)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "        d_loss, accuracy = 0.5*np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        # 生成一批伪图像，训练生成器\n",
    "        z = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = generator.predict(z)\n",
    "        g_loss = gan.train_on_batch(z, real)\n",
    "        \n",
    "        if (iteration + 1) % sample_interval == 0:\n",
    "            losses.append((d_loss, g_loss))\n",
    "            accuracies.append(100.0*accuracy)\n",
    "            iteration_checkpoints.append(iteration + 1)\n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\"%\n",
    "                 (iteration + 1, d_loss, 100.0*accuracy, g_loss))\n",
    "            sample_images(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d90ff5-fb24-416b-a9b7-5cb978a217d9",
   "metadata": {},
   "source": [
    "### Display the generatored images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff85504-17bd-4ad9-ab11-b665680afbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(generator, image_grid_rows=4, image_grid_columns=4):\n",
    "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
    "    gen_imgs = generator.predict(z)\n",
    "    gen_imgs = 0.5*gen_imgs + 0.5\n",
    "    fig, axs = plt.subplots(image_grid_rows,\n",
    "                           image_grid_columns,\n",
    "                           figsize = (4, 4),\n",
    "                           sharex=True,\n",
    "                           sharey=True)\n",
    "    cnt = 0\n",
    "    for i in range(image_grid_rows):\n",
    "        for j in range(image_grid_columns):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d017ac91-dbfa-4006-a804-19e8c645fd5c",
   "metadata": {},
   "source": [
    "### Iter the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289f852-9eed-4088-8834-2f374175d950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.002257]\n",
      "2000 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.003370]\n"
     ]
    }
   ],
   "source": [
    "iterations = 20000\n",
    "batch_size = 128\n",
    "sample_interval = 1000\n",
    "train(iterations, batch_size, sample_interval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
