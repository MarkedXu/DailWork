{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ca0604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def to_var(x):\n",
    "    \"\"\" Make a tensor cuda-erized and requires gradient \"\"\"\n",
    "    return to_cuda(x).requires_grad_()\n",
    "\n",
    "def to_cuda(x):\n",
    "    \"\"\" Cuda-erize a tensor \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return x\n",
    "\n",
    "def get_data(BATCH_SIZE=100):\n",
    "    \"\"\" Load data for binared MNIST \"\"\"\n",
    "    torch.manual_seed(3435)\n",
    "\n",
    "    # Download our data\n",
    "    train_dataset = datasets.MNIST(root='./data/',\n",
    "                                    train=True,\n",
    "                                    transform=transforms.ToTensor(),\n",
    "                                    download=True)\n",
    "\n",
    "    test_dataset = datasets.MNIST(root='./data/',\n",
    "                                   train=False,\n",
    "                                   transform=transforms.ToTensor())\n",
    "\n",
    "    # Use greyscale values as sampling probabilities to get back to [0,1]\n",
    "    train_img = torch.stack([torch.bernoulli(d[0]) for d in train_dataset])\n",
    "    train_label = torch.LongTensor([d[1] for d in train_dataset])\n",
    "\n",
    "    test_img = torch.stack([torch.bernoulli(d[0]) for d in test_dataset])\n",
    "    test_label = torch.LongTensor([d[1] for d in test_dataset])\n",
    "\n",
    "    # MNIST has no official train dataset so use last 10000 as validation\n",
    "    val_img = train_img[-10000:].clone()\n",
    "    val_label = train_label[-10000:].clone()\n",
    "\n",
    "    train_img = train_img[:-10000]\n",
    "    train_label = train_label[:-10000]\n",
    "\n",
    "    # Create data loaders\n",
    "    train = torch.utils.data.TensorDataset(train_img, train_label)\n",
    "    val = torch.utils.data.TensorDataset(val_img, val_label)\n",
    "    test = torch.utils.data.TensorDataset(test_img, test_label)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_iter = torch.utils.data.DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_iter = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    return train_iter, val_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "794ee8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/25 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21529/3757720141.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    230\u001b[0m                            viz=False)\n\u001b[1;32m    231\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     trainer.train(num_epochs=25,\n\u001b[0m\u001b[1;32m    233\u001b[0m                  \u001b[0mG_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                  \u001b[0mD_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_21529/3757720141.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_epochs, G_lr, D_lr, D_steps)\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                     \u001b[0mD_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                     \u001b[0mD_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m                     \u001b[0mD_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0mD_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_21529/3757720141.py\u001b[0m in \u001b[0;36mtrain_D\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Compute vanilla (original paper) D loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mD_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDX_score\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mDG_score\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mD_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, image_size, hidden_dim, z_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(z_dim, hidden_dim)\n",
    "        self.generate = nn.Linear(hidden_dim, image_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        activated = F.relu(self.linear(x))\n",
    "        generation = torch.sigmoid(self.generate(activated))\n",
    "        return generation\n",
    "    \n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_size, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(image_size, hidden_dim)\n",
    "        self.discriminate = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activated = F.relu(self.linear(x))\n",
    "        self.discrimination = torch.sigmoid(self.discriminate(activated))\n",
    "        \n",
    "\n",
    "class NSGAN(nn.Module):\n",
    "    def __init__(self, image_size, hidden_dim, z_dim, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.__dict__.update(locals())\n",
    "        self.G = Generator(image_size, hidden_dim, z_dim)\n",
    "        self.D = Discriminator(image_size, hidden_dim, z_dim)\n",
    "        self.shape = int(image_size ** 0.5)\n",
    "        \n",
    "        \n",
    "class NSGANTrainer(object):\n",
    "    def __init__(self, model, train_iter, val_iter, test_iter, viz=False):\n",
    "        self.model = to_cuda(model)\n",
    "        self.name = model.__class__.__name__\n",
    "        \n",
    "        self.train_iter = train_iter\n",
    "        self.val_iter = val_iter\n",
    "        self.test_iter = test_iter\n",
    "        \n",
    "        self.Glosses = []\n",
    "        self.Dlosses = []\n",
    "        self.viz = viz\n",
    "        self.num_epochs = 0\n",
    "        \n",
    "    def train(self, num_epochs, G_lr=2e-4, D_lr=2e-4, D_steps=1):\n",
    "        G_optimizer = optim.Adam(params=[p for p in self.model.G.parameters()\n",
    "                                        if p.requires_grad], lr=G_lr)\n",
    "        D_optimizer = optim.Adam(params=[p for p in self.model.D.parameters()\n",
    "                                        if p.requires_grad], lr=D_lr)\n",
    "        \n",
    "        epoch_steps = int(np.ceil(len(self.train_iter)/ (D_steps)))\n",
    "        \n",
    "        for epoch in tqdm(range(1, num_epochs+1)):\n",
    "            self.model.train()\n",
    "            G_losses, D_losses = [], []\n",
    "            for _ in range(epoch_steps):\n",
    "                D_step_loss = []\n",
    "                for _ in range(D_steps):\n",
    "                    images = self.process_batch(self.train_iter)\n",
    "                    D_optimizer.zero_grad()\n",
    "                    D_loss = self.train_D(images)\n",
    "                    D_loss.backward()\n",
    "                    D_optimizer.step()\n",
    "                    D_step_loss.append(D_loss.item())\n",
    "                D_losses.append(np.mean(D_step_loss))\n",
    "                G_optimizer.zero_grad()\n",
    "                G_loss = self.train_G(images)\n",
    "                G_losses.append(G_loss.item())\n",
    "                G_loss.backward()\n",
    "                G_optimizer.step()\n",
    "            self.Glosses.extend(G_losses)\n",
    "            self.Dlosses.extend(D_losses)\n",
    "            print(\"Epoch[%d/%d], G Loss: %.4f, D Loss: %.4f\"\n",
    "                   %(epoch, num_epochs, np.mean(G_losses), np.mean(D_losses)))\n",
    "            self.num_epochs += 1\n",
    "\n",
    "            # Visualize generator progress\n",
    "            if self.viz:\n",
    "                self.generate_images(epoch)\n",
    "                plt.show()\n",
    "\n",
    "    def train_D(self, images):\n",
    "        \"\"\" Run 1 step of training for discriminator\n",
    "        Input:\n",
    "            images: batch of images (reshaped to [batch_size, -1])\n",
    "        Output:\n",
    "            D_loss: non-saturing loss for discriminator,\n",
    "            -E[log(D(x))] - E[log(1 - D(G(z)))]\n",
    "        \"\"\"\n",
    "\n",
    "        # Sample noise z, generate output G(z)\n",
    "        noise = self.compute_noise(images.shape[0], self.model.z_dim)\n",
    "        G_output = self.model.G(noise)\n",
    "\n",
    "        # Classify the generated and real batch images\n",
    "        DX_score = self.model.D(images) # D(x)\n",
    "        DG_score = self.model.D(G_output) # D(G(z))\n",
    "\n",
    "        # Compute vanilla (original paper) D loss\n",
    "        D_loss = -torch.mean(torch.log(DX_score + 1e-8) + torch.log(1 - DG_score + 1e-8))\n",
    "        \n",
    "        return D_loss\n",
    "\n",
    "    def train_G(self, images):\n",
    "        \"\"\" Run 1 step of training for generator\n",
    "        Input:\n",
    "            images: batch of images reshaped to [batch_size, -1]\n",
    "        Output:\n",
    "            G_loss: non-saturating loss for how well G(z) fools D,\n",
    "            -E[log(D(G(z)))]\n",
    "        \"\"\"\n",
    "\n",
    "        # Get noise (denoted z), classify it using G, then classify the output\n",
    "        # of G using D.\n",
    "        noise = self.compute_noise(images.shape[0], self.model.z_dim) # (z)\n",
    "        G_output = self.model.G(noise) # G(z)\n",
    "        DG_score = self.model.D(G_output) # D(G(z))\n",
    "\n",
    "        # Compute the non-saturating loss for how D did versus the generations\n",
    "        # of G using sigmoid cross entropy\n",
    "        G_loss = -torch.mean(torch.log(DG_score + 1e-8))\n",
    "\n",
    "        return G_loss\n",
    "\n",
    "    def compute_noise(self, batch_size, z_dim):\n",
    "        \"\"\" Compute random noise for the generator to learn to make images from \"\"\"\n",
    "        return to_cuda(torch.randn(batch_size, z_dim))\n",
    "\n",
    "    def process_batch(self, iterator):\n",
    "        \"\"\" Generate a process batch to be input into the discriminator D \"\"\"\n",
    "        images, _ = next(iter(iterator))\n",
    "        images = to_cuda(images.view(images.shape[0], -1))\n",
    "        return images\n",
    "\n",
    "    def generate_images(self, epoch, num_outputs=36, save=True):\n",
    "        \"\"\" Visualize progress of generator learning \"\"\"\n",
    "        # Turn off any regularization\n",
    "        self.model.eval()\n",
    "\n",
    "        # Sample noise vector\n",
    "        noise = self.compute_noise(num_outputs, self.model.z_dim)\n",
    "\n",
    "        # Transform noise to image\n",
    "        images = self.model.G(noise)\n",
    "\n",
    "        # Reshape to square image size\n",
    "        images = images.view(images.shape[0],\n",
    "                             self.model.shape,\n",
    "                             self.model.shape,\n",
    "                             -1).squeeze()\n",
    "\n",
    "        # Plot\n",
    "        plt.close()\n",
    "        grid_size, k = int(num_outputs**0.5), 0\n",
    "        fig, ax = plt.subplots(grid_size, grid_size, figsize=(5, 5))\n",
    "        for i, j in product(range(grid_size), range(grid_size)):\n",
    "            ax[i,j].get_xaxis().set_visible(False)\n",
    "            ax[i,j].get_yaxis().set_visible(False)\n",
    "            ax[i,j].imshow(images[k].data.numpy(), cmap='gray')\n",
    "            k += 1\n",
    "\n",
    "        # Save images if desired\n",
    "        if save:\n",
    "            outname = '../viz/' + self.name + '/'\n",
    "            if not os.path.exists(outname):\n",
    "                os.makedirs(outname)\n",
    "            torchvision.utils.save_image(images.unsqueeze(1).data,\n",
    "                                         outname + 'reconst_%d.png'\n",
    "                                         %(epoch), nrow=grid_size)\n",
    "\n",
    "    def viz_loss(self):\n",
    "        \"\"\" Visualize loss for the generator, discriminator \"\"\"\n",
    "        # Set style, figure size\n",
    "        plt.style.use('ggplot')\n",
    "        plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "\n",
    "        # Plot Discriminator loss in red, Generator loss in green\n",
    "        plt.plot(np.linspace(1, self.num_epochs, len(self.Dlosses)),\n",
    "                 self.Dlosses,\n",
    "                 'r')\n",
    "        plt.plot(np.linspace(1, self.num_epochs, len(self.Dlosses)),\n",
    "                 self.Glosses,\n",
    "                 'g')\n",
    "\n",
    "        # Add legend, title\n",
    "        plt.legend(['Discriminator', 'Generator'])\n",
    "        plt.title(self.name)\n",
    "        plt.show()\n",
    "\n",
    "    def save_model(self, savepath):\n",
    "        \"\"\" Save model state dictionary \"\"\"\n",
    "        torch.save(self.model.state_dict(), savepath)\n",
    "\n",
    "    def load_model(self, loadpath):\n",
    "        \"\"\" Load state dictionary into model \"\"\"\n",
    "        state = torch.load(loadpath)\n",
    "        self.model.load_state_dict(state)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Load in binarized MNIST data, separate into data loaders\n",
    "    train_iter, val_iter, test_iter = get_data()\n",
    "\n",
    "    # Init model\n",
    "    model = NSGAN(image_size=784,\n",
    "                  hidden_dim=400,\n",
    "                  z_dim=20)\n",
    "\n",
    "    # Init trainer\n",
    "    trainer = NSGANTrainer(model=model,\n",
    "                           train_iter=train_iter,\n",
    "                           val_iter=val_iter,\n",
    "                           test_iter=test_iter,\n",
    "                           viz=False)\n",
    "    # Train\n",
    "    trainer.train(num_epochs=25,\n",
    "                 G_lr=2e-4,\n",
    "                 D_lr=2e-4,\n",
    "                 D_steps=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
