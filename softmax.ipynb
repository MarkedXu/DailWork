{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43d91365-59cb-4ab6-9355-3c78a46395b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd.function import Function\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "# from model_utils import Centerloss\n",
    "# from model_utils import Net\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "batch_size = 100\n",
    "num_opech = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15eaf135-79bc-47dc-8ca7-32f363dc0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n",
    "        self.prelu1_1 = nn.PReLU()\n",
    "        self.conv1_2 = nn.Conv2d(32, 32, kernel_size=5, padding=2)\n",
    "        self.prelu1_2 = nn.PReLU()\n",
    "        self.conv2_1 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
    "        self.prelu2_1 = nn.PReLU()\n",
    "        self.conv2_2 = nn.Conv2d(64, 64, kernel_size=5, padding=2)\n",
    "        self.prelu2_2 = nn.PReLU()\n",
    "        self.conv3_1 = nn.Conv2d(64, 128, kernel_size=5, padding=2)\n",
    "        self.prelu3_1 = nn.PReLU()\n",
    "        self.conv3_2 = nn.Conv2d(128, 128, kernel_size=5, padding=2)\n",
    "        self.prelu3_2 = nn.PReLU()\n",
    "        self.preluip1 = nn.PReLU()\n",
    "        self.ip1 = nn.Linear(128 * 3 * 3, 2)\n",
    "        self.ip2 = nn.Linear(2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.prelu1_1(self.conv1_1(x))\n",
    "        x = self.prelu1_2(self.conv1_2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.prelu2_1(self.conv2_1(x))\n",
    "        x = self.prelu2_2(self.conv2_2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.prelu3_1(self.conv3_1(x))\n",
    "        x = self.prelu3_2(self.conv3_2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 128 * 3 * 3)\n",
    "        ip1 = self.preluip1(self.ip1(x))\n",
    "        ip2 = self.ip2(ip1)\n",
    "        return ip1, ip2\n",
    "    \n",
    "class CenterLoss(nn.Module):\n",
    "    def __init__(self, num_classes, feat_dim):\n",
    "        super(CenterLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.feat_dim = feat_dim\n",
    "        self.centers = nn.Parameter(torch.randn(num_classes, feat_dim))\n",
    "        self.centerlossfunction = CenterlossFunction.apply\n",
    "\n",
    "    def forward(self, y, feat):\n",
    "        # To squeeze the Tenosr\n",
    "        batch_size = feat.size(0)\n",
    "        feat = feat.view(batch_size, 1, 1, -1).squeeze()\n",
    "        # To check the dim of centers and features\n",
    "        if feat.size(1) != self.feat_dim:\n",
    "            raise ValueError(\"Center's dim: {0} should be equal to input feature's dim: {1}\".format(self.feat_dim,feat.size(1)))\n",
    "        return self.centerlossfunction(feat, y, self.centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "559e0e62-1362-4dab-acdb-23f031437000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(feat, labels, epoch):\n",
    "    plt.ion()\n",
    "    c = ['#ff0000', '#ffff00', '#00ff00', '#00ffff', '#0000ff',\n",
    "         '#ff00ff', '#990000', '#999900', '#009900', '#009999']\n",
    "    plt.clf()\n",
    "    for i in range(10):\n",
    "        plt.plot(feat[labels == i, 0], feat[labels == i, 1], '.', c=c[i])\n",
    "    plt.legend(['0', '1', '2', '3', '4', '5', '6', '7', '8','9'], loc='uper right')\n",
    "    plt.text(-4.8, 4.6, \"epoch=%d\" % epoch)\n",
    "    plt.savefig('./images/softmax_loss_epoch=%d.jpg' % epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "340a5669-686c-416a-bed1-dd5c5295a8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loder, model, use_cuda):\n",
    "    correct=0\n",
    "    total=0\n",
    "    for i, (data, target) in enumerate(test_loder):\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        ip1, logits = model(data)\n",
    "        _, predicted = torch.max(logits.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target.data).sum()\n",
    "    print('Test Accuracy of the model on the 10000 test images: %f %%' % (100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d3c7bd8-2953-4a4f-8632-63bb60e4522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, use_cuda):\n",
    "    ip1_loader = []\n",
    "    idx_loader = []\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        feats, logits = model(data)\n",
    "        loss = criterion[0](logits, target)\n",
    "\n",
    "        _, predicted = torch.max(logits.data, 1)\n",
    "        accuracy = (target.data == predicted).float().mean()\n",
    "\n",
    "        optimizer[0].zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer[0].step()\n",
    "\n",
    "        ip1_loader.append(feats)\n",
    "        idx_loader.append((target))\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print('Epoch [%d], Iter [%d/%d] Loss: %.4f Acc %.4f'\n",
    "                  % (epoch, i + 1, len(train_loader) // batch_size, loss.data[0], accuracy))\n",
    "\n",
    "    feat = torch.cat(ip1_loader, 0)\n",
    "    labels = torch.cat(idx_loader, 0)\n",
    "    visualize(feat.data.cpu().numpy(), labels.data.cpu().numpy(), epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b6e551a-fb1b-4546-bd5e-0abf4a88dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if torch.cuda.is_available():\n",
    "        use_cuda = True\n",
    "    else:\n",
    "        use_cuda = False\n",
    "    # Dataset\n",
    "    trainset = datasets.MNIST('./data/', download=True, train=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "    train_loader = DataLoader(trainset, batch_size=100, shuffle=True, num_workers=4)\n",
    "\n",
    "    testset = datasets.MNIST('./data/', download=True, train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "    test_loader = DataLoader(testset, batch_size=100, shuffle=True, num_workers=4)\n",
    "    \n",
    "    # Model\n",
    "    model = Net()\n",
    "    \n",
    "    # NLLLoss\n",
    "    nllloss = nn.CrossEntropyLoss()\n",
    "    if use_cuda:\n",
    "        nllloss = nllloss.cuda()\n",
    "        model = model.cuda()\n",
    "    criterion = [nllloss]\n",
    "    \n",
    "    # optimizer\n",
    "    optimizer4nn = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "    sheduler = lr_scheduler.StepLR(optimizer4nn, 20, gamma=0.8)\n",
    "    \n",
    "    for epoch in range(num_opech):\n",
    "        sheduler.step()\n",
    "        train(train_loader, model, criterion, [optimizer4nn], epoch +1, use_cuda)\n",
    "        torch.save(model, './model/softmax_net_'+str(epoch+1)+'.model')\n",
    "        test(test_loader, model, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ecf360c-03e4-4305-a240-7f4946e3a88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/anaconda3/envs/Pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4157/217905245.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4157/2472475385.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_opech\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0msheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moptimizer4nn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./model/softmax_net_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4157/3201936152.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, use_cuda)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             print('Epoch [%d], Iter [%d/%d] Loss: %.4f Acc %.4f'\n\u001b[0;32m---> 24\u001b[0;31m                   % (epoch, i + 1, len(train_loader) // batch_size, loss.data[0], accuracy))\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip1_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "795c07e4-70df-43ae-9664-9cc1cc235101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
