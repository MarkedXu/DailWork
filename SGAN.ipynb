{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efaa8488",
   "metadata": {},
   "source": [
    "## Chapter 7: Semi-Supervised GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ecccf4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.engine.training_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/PycharmProject/Jupyter_dir/ipykernel_34379/3353102831.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvanced_activations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrappers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/keras/callbacks/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallbackList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/keras/callbacks/callbacks.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProgbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstandardize_input_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.engine.training_utils'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import (Activation, BatchNormalization, Concatenate, Dense,\n",
    "                          Dropout, Flatten, Input, Lambda, Reshape)\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3093af",
   "metadata": {},
   "source": [
    "Using Tensorflow backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0976c597",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed68b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, num_labeled):\n",
    "        \n",
    "        # Number labeled example to use fro training\n",
    "        self.num_labeled = num_labeled\n",
    "        # Load the MNIST dataset\n",
    "        (self.x_train, self.y_train), (self.x_test, self.y_test) = mnist.load_data()\n",
    "        \n",
    "        def preprocess_imgs(x):\n",
    "            #Reshape [0, 255] grayscale values to [-1, 1]\n",
    "            x = (x.astype(np.float32) - 127.5)/127.5\n",
    "            # Expand image dimensions to width x height x channels\n",
    "            x = np.expand_dims(x ,axis=3)\n",
    "            return x\n",
    "        def preprocess_labels(y):\n",
    "            return y.reshape(-1, 1)\n",
    "        \n",
    "        # Training data\n",
    "        self.x_train = preprocess_imgs(self.x_train)\n",
    "        self.y_train = preprocess_labels(self.y_train)\n",
    "        \n",
    "        # Testing data\n",
    "        self.x_test = preprocess_imgs(self.x_test)\n",
    "        self.y_test = preprocess_labels(self.y_test)\n",
    "        \n",
    "    def batch_labeled(self, batch_size):\n",
    "        # Get a random batch of labeled images and their labels\n",
    "        idx = np.random.randint(0, self.num_labeled, batch_size)\n",
    "        imgs = self.x_train[idx]\n",
    "        labels = self.y_train[idx]\n",
    "        return imgs,labels\n",
    "    \n",
    "    def batch_unlabeled(self, batch_size):\n",
    "        # Get a random batch of unlabeled images\n",
    "        idx = np.random.randint(self.num_labeled, self.x_train.shape[0], batch_size)\n",
    "        imgs = self.x_train[idx]\n",
    "        return imgs\n",
    "    \n",
    "    def training_set(self):\n",
    "        x_train = self.x_train[range(self.num_labeled)]\n",
    "        y_train = self.y_train[range(self.num_labeled)]\n",
    "        return x_train, y_train\n",
    "    \n",
    "    def test_set(self):\n",
    "        return self.x_test, self.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd23c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of labeled examples to use (rest will be used as unlabeled)\n",
    "num_labeled = 100\n",
    "dataset = Dataset(num_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e9f6d3",
   "metadata": {},
   "source": [
    "## Semi-Supervied GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce2a03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "\n",
    "# Input image dimensions\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "# Size of the noise vector, used as input to the generator\n",
    "z_dim = 100\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a4547b",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe5d47b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(z_dim):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Reshape input into 7x7x256 tensor via a fully connected layer\n",
    "    model.add(Dense(256*7*7, input_dim=z_dim))\n",
    "    model.add(Reshape((7,7,256)))\n",
    "    \n",
    "    # Transposed convolution layer, from 7x7x256 into 14x14x128 tensor\n",
    "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
    "    \n",
    "    # Batch normalization\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # Leak Relu activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    # Transposed convolution layer, from 14x14x128 to 14x14x64 tensor\n",
    "    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n",
    "    \n",
    "    # Batch normalization\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # Leak Relu activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    # Transposed convolution layer, form 14x14x64 to 28x28x1 tensor\n",
    "    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))\n",
    "    \n",
    "    # Output layer with tanh activation\n",
    "    model.add(Activation('tanh'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138f6c5b",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2431742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Convolutional layer, from 28x28x1 into 14x14x32 tensor\n",
    "    model.add(Conv2D(32,\n",
    "                    kernel_size=3,\n",
    "                    strides=2,\n",
    "                    input_shape=img_shape,\n",
    "                    padding='same'))\n",
    "    \n",
    "    # Leak Relu activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    # Convolutional layer, from 14x14x28 into 7x7x64 tensor\n",
    "    model.add(Conv2D(64,\n",
    "                    kernel_size=3,\n",
    "                    strides=2,\n",
    "                    input_shape=img_shape,\n",
    "                    padding='same'))\n",
    "    \n",
    "    # Batch normalization\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # Leak Relu activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    # COnvolutional layer, from 7x7x14 tensor into 3x3x28 tensor\n",
    "    model.add(Conv2D(128,\n",
    "                    kernel_size=3,\n",
    "                    strides=2,\n",
    "                    input_shape=img_shape,\n",
    "                    padding='same'))\n",
    "    \n",
    "    # Batch normalization\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # Leak Relu activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    # Dropout\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # Flatten the tensor\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Fully connected layer with num_classes neurons\n",
    "    model.add(Dense(num_classes))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55d278f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator_supervised(discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(discriminator)\n",
    "    \n",
    "    # Softmax activation, giving predicted probability distribution over the real classes\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eb26f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator_unsupervised(discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(discriminator)\n",
    "    \n",
    "    def predict(x):\n",
    "        \n",
    "        # Transform distribution over real classes into a binary real-vs-fake probability\n",
    "        prediction = 1.0 - (1.0/\n",
    "                            (K.sum(K.exp(x), axis=-1, keepdims=True) + 1.0))\n",
    "        return prediction\n",
    "    \n",
    "    # Real-vs-Fake output neuron defined above\n",
    "    model.add(Lambda(predict))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26d66c1",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ad924cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Combined the Genrator-> DIscriminator model\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc86631",
   "metadata": {},
   "source": [
    "## Discrimiantor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc299934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-18 14:04:19.554220: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-03-18 14:04:19.597900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-18 14:04:19.598186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1050 Ti computeCapability: 6.1\n",
      "coreClock: 1.392GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2022-03-18 14:04:19.598280: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/ffmpeg/lib:/usr/local/cuda-10.1/lib64\n",
      "2022-03-18 14:04:19.598372: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/ffmpeg/lib:/usr/local/cuda-10.1/lib64\n",
      "2022-03-18 14:04:19.598451: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/ffmpeg/lib:/usr/local/cuda-10.1/lib64\n",
      "2022-03-18 14:04:19.599848: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-18 14:04:19.600117: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-18 14:04:19.600209: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/ffmpeg/lib:/usr/local/cuda-10.1/lib64\n",
      "2022-03-18 14:04:19.600288: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/ffmpeg/lib:/usr/local/cuda-10.1/lib64\n",
      "2022-03-18 14:04:19.600365: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/ffmpeg/lib:/usr/local/cuda-10.1/lib64\n",
      "2022-03-18 14:04:19.600376: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-03-18 14:04:19.600755: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-18 14:04:19.601471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-18 14:04:19.601485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n"
     ]
    }
   ],
   "source": [
    "# Core Discriminator network\n",
    "# These layers are shred during supervised and unsupervised training\n",
    "discriminator_net = build_discriminator(img_shape)\n",
    "\n",
    "# Build & Compile the discriminator for unsupervised training\n",
    "discriminator_supervised = build_discriminator_supervised(discriminator_net)\n",
    "discriminator_supervised.compile(loss='categorical_crossentropy',\n",
    "                                metrics=['accuracy'],\n",
    "                                optimizer=adam_v2.Adam())\n",
    "\n",
    "# Build & Compile the Discriminator for unsupervised training\n",
    "discriminator_unsupervised = build_discriminator_unsupervised(discriminator_net)\n",
    "discriminator_unsupervised.compile(loss='binary_crossentropy',\n",
    "                                  optimizer=adam_v2.Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab161055",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8698315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the generator\n",
    "generator = build_generator(z_dim)\n",
    "\n",
    "# Keep Discriminator's parameters constant for Generator training\n",
    "discriminator_unsupervised.trainable = False\n",
    "\n",
    "# Build and Compile GAN model with fixed Discriminator to train the Generator\n",
    "# Note that we are using the Discriminator version with unsupervised output\n",
    "gan = build_gan(generator, discriminator_unsupervised)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam_v2.Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf2f8fc",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a828e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_losses = []\n",
    "iteration_checkpoints = []\n",
    "\n",
    "def train(iterations, batch_size, sample_interval):\n",
    "    # Labels for real images: all ones\n",
    "    real = np.ones((batch_size, 1))\n",
    "    \n",
    "    # Labels for fake images: all zeros\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        # --------------\n",
    "        # Training D----\n",
    "        # --------------\n",
    "        # Get labeled examples\n",
    "        imgs, labels = dataset.batch_labeled(batch_size)\n",
    "        \n",
    "        # One-hot encode labels\n",
    "        labels = utils.to_catagorical(labels, num_classes=num_classes)\n",
    "        \n",
    "        # Get unlabeled examples\n",
    "        imgs_unlabeled = dataset.batch_unlabeled(batch_size)\n",
    "        \n",
    "        # Generate a batch of fake images\n",
    "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        gen_imgs = generator.predict(z)\n",
    "        \n",
    "        # Train on real labeled example\n",
    "        d_loss_supervised, accuracy = discriminator_supervised.train_on_batch(imgs, labels)\n",
    "        \n",
    "        # Train on real unlabeled examples\n",
    "        d_loss_real = discriminator_unsupervised.train_on_batch(imgs_unlabeled, real)\n",
    "        \n",
    "        # Train on fake examples\n",
    "        d_loss_fake = discriminator_unsupervised.train_on_batch(gen_imgs, fake)\n",
    "        d_loss_unsupervised = 0.5*np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        # -------------\n",
    "        # Training G---\n",
    "        # -------------\n",
    "        \n",
    "        # Gnerate a batch of fake images\n",
    "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        gen_imgs = generator.predict(z)\n",
    "        \n",
    "        # Train G\n",
    "        g_loss = gan.train_on_batch(z, np.ones((batch_size, 1)))\n",
    "        if (iteration + 1) % sample_interval == 0:\n",
    "            # Save D supervised classification loss to be plotted after training\n",
    "            supervised_losses.append(d_loss_supervised)\n",
    "            iteration_checkpoints.append(iteration + 1)\n",
    "            # Output training progress\n",
    "            print(\n",
    "                \"%d [D loss supervised: %.4f, acc.: %.2f%%] [D loss unsupervised: %.4f] [G loss: %f]\"\n",
    "                % (iteration + 1, d_loss_supervised, 100 * accuracy,\n",
    "                   d_loss_unsupervised, g_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5a4c60",
   "metadata": {},
   "source": [
    "## Train the Model and Inspect Output\n",
    "Note that the 'Discrepancy between trainable weights anf collected trainable' warning from Keras is expected. It is by design: The G's trainable parameters are intentionally held constant during D training and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cdb3090",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.keras.utils' has no attribute 'to_catagorical'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/PycharmProject/Jupyter_dir/ipykernel_34379/4118514701.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msample_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Train teh SGAN for the specified number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProject/Jupyter_dir/ipykernel_34379/3199202863.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(iterations, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# One-hot encode labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_catagorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Get unlabeled examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.keras.utils' has no attribute 'to_catagorical'"
     ]
    }
   ],
   "source": [
    "# Set hyperparameters\n",
    "iterations = 8000\n",
    "batch_size = 32\n",
    "sample_interval = 800\n",
    "# Train teh SGAN for the specified number of iterations\n",
    "train(iterations, batch_size, sample_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e06d4870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
